{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04b2712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e552cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0019899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset from Hugging Face\n",
    "def load_ui_dataset():\n",
    "    dataset = load_dataset(\"mrtoy/mobile-ui-design\")\n",
    "    print(dataset)  # Explore dataset structure and features\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2747681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the language model (NLP)\n",
    "def load_language_model():\n",
    "    model_name = \"gpt-neo-1.3B\"  # or any other model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dd25325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load the image generation model (CV)\n",
    "def load_image_generator():\n",
    "    # Using a pre-trained stable diffusion model for image generation\n",
    "    stable_diffusion_model = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\").to(\"cuda\")\n",
    "    return stable_diffusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12a343d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Generate text prompts based on user input\n",
    "def generate_prompt(tokenizer, model, user_input):\n",
    "    inputs = tokenizer(user_input, return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs)\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bfe30c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate an image from the prompt using Stable Diffusion\n",
    "def generate_ui_image(generator_model, text_prompt):\n",
    "    image = generator_model(text_prompt).images[0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39850aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Main function to interact with the system\n",
    "def main():\n",
    "    # Load dataset, models\n",
    "    dataset = load_ui_dataset()\n",
    "    tokenizer, lang_model = load_language_model()\n",
    "    img_gen_model = load_image_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "363f9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input (can also be command-line input)\n",
    "user_input = \"Generate a simple login page with two input fields and a submit button\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb32df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c9c0840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text Prompt: Generate a simple login page with two input fields and a submit button.\n",
      "\n",
      "This is a good solution for users who need to start a new account, but it doesn't work with a real login. For example, if you are a data-driven company, you may want to create a login form with only two inputs, an input field and an submitbutton. This way, users can easily add and edit any number of fields, and they can then have their data saved in the same\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load the tokenizer and the language model (GPT-2 in this case)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "lang_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Function to generate a text prompt using the LLM\n",
    "def generate_prompt(tokenizer, model, user_input):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize the input text for the model\n",
    "    inputs = tokenizer(user_input, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate the text prompt using the model\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_length=100,              # Maximum length of generated text\n",
    "        num_return_sequences=1,       # Generate only one sequence\n",
    "        do_sample=True,               # Enable sampling for more creativity\n",
    "        top_k=50,                     # Top-k sampling\n",
    "        top_p=0.95,                   # Nucleus sampling\n",
    "        temperature=0.7,              # Control randomness\n",
    "        no_repeat_ngram_size=2        # Prevent repetition\n",
    "    )\n",
    "\n",
    "    # Decode the generated tokens into readable text\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    return decoded_output\n",
    "\n",
    "# Example usage\n",
    "user_input = \"Generate a simple login page with two input fields and a submit button\"\n",
    "text_prompt = generate_prompt(tokenizer, lang_model, user_input)\n",
    "print(f\"Generated Text Prompt: {text_prompt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07a7ea27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "lang_model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab177f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "lang_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e1c09f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Generate text prompts based on user input\n",
    "def generate_prompt(tokenizer, model, user_input):\n",
    "    inputs = tokenizer(user_input, return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs)\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return decoded_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fd14eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate an image from the prompt using Stable Diffusion\n",
    "def generate_ui_image(generator_model, text_prompt):\n",
    "    image = generator_model(text_prompt).images[0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46c0b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Main function to interact with the system\n",
    "def main():\n",
    "    # Load dataset, models\n",
    "    dataset = load_ui_dataset()\n",
    "    tokenizer, lang_model = load_language_model()\n",
    "    img_gen_model = load_image_generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42f3a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input (can also be command-line input)\n",
    "user_input = \"Generate a simple login page with two input fields and a submit button\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f20a1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\Documents\\Python Scripts\\lib\\site-packages\\transformers\\generation\\utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text Prompt: Generate a simple login page with two input fields and a submit button.\n"
     ]
    }
   ],
   "source": [
    " # Generate design description using LLM\n",
    "text_prompt = generate_prompt(tokenizer, lang_model, user_input)\n",
    "print(f\"Generated Text Prompt: {text_prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfccc551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the UI design image\n",
    "def generate_ui_image(img_gen_model, text_prompt):\n",
    "    # Generate an image from the text prompt\n",
    "    image = img_gen_model(text_prompt).images[0]\n",
    "    \n",
    "    # Save or display the image (optional)\n",
    "    image.save(\"generated_ui_design.png\")\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41493d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ccd6ab49d5429eb80b7827a173591f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7036\\3919914272.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Load the image generation model (Stable Diffusion)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mimg_gen_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_image_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7036\\380709185.py\u001b[0m in \u001b[0;36mload_image_generator\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_image_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Using a pre-trained stable diffusion model for image generation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mstable_diffusion_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStableDiffusionPipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CompVis/stable-diffusion-v1-4\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstable_diffusion_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\lib\\site-packages\\diffusers\\pipelines\\pipeline_utils.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    429\u001b[0m                 )\n\u001b[0;32m    430\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m                 \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m             if (\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2956\u001b[0m                     \u001b[1;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2957\u001b[0m                 )\n\u001b[1;32m-> 2958\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2960\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1172\u001b[0m                     \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m     def register_full_backward_pre_hook(\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m                 \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m                 \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m                 \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m                 \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m                 \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1158\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m                     )\n\u001b[1;32m-> 1160\u001b[1;33m                 return t.to(\n\u001b[0m\u001b[0;32m   1161\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    303\u001b[0m             )\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cuda_getDeviceCount\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the image generation model (Stable Diffusion)\n",
    "    img_gen_model = load_image_generator()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a975a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
      "Requirement already satisfied: torch in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10aae457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8d44bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lenovo\\documents\\python scripts\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7269b3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: C:\\Users\\LENOVO\\Documents\\Python\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8141f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
